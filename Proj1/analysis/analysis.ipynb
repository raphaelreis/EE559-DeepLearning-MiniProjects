{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "import utils.loader as ld\n",
    "import utils.image_processing as ip\n",
    "%aimport models.raph_model \n",
    "%aimport utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X, tr_y, tr_classes, te_X, te_y, te_classes = ld.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.imshow(tr_X[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_X = tr_X.view(-1, 1, 14, 14).squeeze()\n",
    "tr_classes = tr_classes.view(-1, 1).squeeze()\n",
    "te_X = te_X.view(-1, 1, 14, 14).squeeze()\n",
    "te_classes = te_classes.view(-1, 1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    \n",
    "tr_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_5(nn.Module):\n",
    "    \"\"\" nn.Linear(84, 10)(\n",
    "        nn.Linear(120, 84)(\n",
    "        nn.Linear(16 * 5 * 5, 120)(\n",
    "            nn.Conv2d(6, 16, 5)(\n",
    "                nn.MaxPool2d(2, 2)(\n",
    "                    nn.Conv2d(2, 6, (5, 5))(tr_X))).view(-1, 16*5*5)))) \"\"\"  \n",
    "                      \n",
    "    def __init__(self):\n",
    "        super(LeNet_5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (1, 1))\n",
    "        self.pool = nn.MaxPool2d((2, 2), stride=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (1, 1))\n",
    "        self.conv3 = nn.Conv2d(16, 120, (1, 1))\n",
    "        self.fc1 = nn.Linear(17280, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1) # !!!!\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(2, 10, kernel_size=5)\n",
    "#         self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "#         self.conv2_drop = nn.Dropout2d()\n",
    "#         self.fc1 = nn.Linear(320, 50)\n",
    "#         self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "#         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         x = x.view(-1, 320)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.dropout(x, training=self.training)\n",
    "#         x = self.fc2(x)\n",
    "#         return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epoch, tr_X, tr_y):\n",
    "    model.train()\n",
    "    for bc, (input_, target) in enumerate(zip(tr_X.split(batch_size), tr_y.split(batch_size))):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if bc % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, bc * len(input_), len(tr_X),\n",
    "                100. * bc / len(tr_X), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (model, criterion, te_X, te_y):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in zip(te_X.split(batch_size), te_y.split(batch_size)):\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(tr_X)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(tr_X),\n",
    "        100. * correct / len(tr_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tr_X[:64, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, nb_epochs, batch_size = 1e-1, 10, 64\n",
    "model = LeNet_5()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "mu, std = tr_X.mean(), tr_X.std()\n",
    "tr_X.sub_(mu).div_(std)\n",
    "\n",
    "mu, std = te_X.mean(), te_X.std()\n",
    "te_X = te_X.sub_(mu).div_(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, nb_epochs):\n",
    "        train(model, optimizer, criterion, epoch, tr_X, tr_y)\n",
    "        test(model, criterion, te_X, te_y)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit628522e40ce24b919f04c033e4c78aa7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
